## 决策树
### 决策树概述

`决策树（Decision Tree）算法是一种基本的分类与回归方法，是经常使用的数据挖掘算法之一。这章只讨论用于分类的决策树。`

`决策树模型呈树型结构，在分类问题中，表示基于特征对实例进行分类的过程，它可以认为是if then规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布。`

`决策树学习通常包括3个步骤：特征选择、决策生成、决策树的生成和决策树的修剪。`
### 决策树 场景

* 一个叫做“二十个问题”的游戏，游戏的规则很简单：参与游戏的一方在乃亥中想某个事物，其他参与者向他提问，只允许提问20个问题，问题的答案也只能用对或错回答。问问题的人通过推断分解，逐步缩小待猜测事务的范围，最后得到游戏的答案

* 一个邮件分类系统大致工作流程如下

        if(发送邮件地址名地址为*****==true)
        {
            无聊时需要阅读的邮件；
        }
        else
        {
            if(包含单词曲棍球的邮件==true)
            {
                需要及时处理的朋友邮件；
            }
            else
            {
                无需阅读的垃圾邮件；
            }
        }
        /*首先检测发送邮件域名地址。如果域名地址为*****，则将其放在分类“无聊时需要阅读的邮件“中
        如果邮件不是来自这个域名，则检测邮件是否包含单词”曲棍球“，如果包含则将邮件归类到”需要及时处理的朋友邮件“，如果不包含则将邮件归类到”无需阅读的垃圾邮件“*/

* 决策树的定义：分类决策树模型是一种描述队实力进行分类的树形结构。决策树有节点（NODE）和有向边(Directed Edge)组成。节点有两种类型：内部节点(Internal Node)和叶节点(Leaf Node)内部节点表示一个特征或属性(Features)叶节点表示一个类(Labels)

* 用决策树对需要测试的实例进行分类：从根节点开始，对实例的某一特征进行测试，根据测试结果，将实力分配到其子节点；这时，每一个子节点对应着该特征的一个取值，如此递归地对实例进行测试并分配，直至到达叶节点。最后将实例分配到叶节点的类中。


### 决策树 原理
#### 决策树须知概念
* 信息熵&信息增益
  * 熵(Entropy)：熵指的是体系的混乱程度，在不同的学科中也有引申出的更为具体的定义，是各领域十分重要的参量。
  * 信息论(Information Theory)中的熵（香农熵）：是一种信息的度量方式，表示信息的混乱程度，也就是说：信息越有序，信息熵越低。
  * 信息增益(Information Gain):在划分数据集前后信息发生变化称为信息增益

#### 决策树工作原理
* 如何构造一个决策树？使用CreatBranch()的方法，如下所示：

        def CreatBranch():
        ...
        运用迭代的思想（可以搜索recursion，甚至是dynamic programing）
        ...
            监测数据集中的所有数据分类标签是否相同：
            if so return 类标签
            Else:
                寻找划分数据集的最好特征(划分之后信息熵最小，也就是信息熵最大的特征)
                划分数据集
                创建分支节点
                    for 每个划分的子集
                        调用函数CreatBranch(创建分支的函数)并增加返回结果到分支节点中
            return 分支节点

#### 决策树开发流程

        收集数据：可以使用任何方法。
        准备数据：树构造算法（这里使用的是ID3算法，只是用于标称型数据，这就是为什么数值型数据必须离散化，还有其他的树构造算法，比如CART）
        分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期。
        训练算法：构造树的数据结构
        测试算法：使用训练好的树计算错误率
        使用算法：可适用于二年和监督学习任务，而使用决策树可以更好地理解数据的内在含义



#### 决策树 算法特点

        优点：计算复杂度不高，输出结果易于理解，数据有缺失也能跑，可以不处理相关特征。
        缺点：容易过拟合
        适用数据类型：数值型和标称型